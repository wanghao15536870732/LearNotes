{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络 --- 从0开始\n",
    "\n",
    "之前的教程里，在输入神经网络前我们讲输入图片直接转成了向量。这样做有两个不好的地方：\n",
    "\n",
    "+ 在图片里相近的像素在向量表示里可能很远，从而模型很难捕获他们的空间关系。\n",
    "+ 对于大图片输入，模型可能会很大。例如输入是$256\\times256\\times3$的照片，输入层是1000，那么这一层的模型大小是将近1GB.\n",
    "\n",
    "\n",
    "# 二维卷积层\n",
    "\n",
    "卷积神经网络（convolutional neural network）是含有卷积层（convolutional layer）的神经网络。本章中介绍的卷积神经网络均使用最常见的二维卷积层。它有高和宽两个空间维度，常用来处理图像数据。本节中，我们将介绍简单形式的二维卷积层的工作原理。\n",
    "\n",
    "\n",
    "## 二维互相关运算\n",
    "\n",
    "虽然卷积层得名于卷积（convolution）运算，但我们通常在卷积层中使用更加直观的互相关（cross-correlation）运算。在二维卷积层中，一个二维输入数组和一个二维核（kernel）数组通过互相关运算输出一个二维数组。\n",
    "我们用一个具体例子来解释二维互相关运算的含义。如图5.1所示，输入是一个高和宽均为3的二维数组。我们将该数组的形状记为$3 \\times 3$或（3，3）。核数组的高和宽分别为2。该数组在卷积计算中又称卷积核或过滤器（filter）。卷积核窗口（又称卷积窗口）的形状取决于卷积核的高和宽，即$2 \\times 2$。图5.1中的阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：$0\\times0+1\\times1+3\\times2+4\\times3=19$。\n",
    "\n",
    "![二维互相关运算](./imgs/no_padding_no_strides.gif)\n",
    "\n",
    "在二维互相关运算中，卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。当卷积窗口滑动到某一位置时，窗口中的输入子数组与核数组按元素相乘并求和，得到输出数组中相应位置的元素。图5.1中的输出数组高和宽分别为2，其中的4个元素由二维互相关运算得出：\n",
    "\n",
    "$$\n",
    "0\\times0+1\\times1+3\\times2+4\\times3=19,\\\\\n",
    "1\\times0+2\\times1+4\\times2+5\\times3=25,\\\\\n",
    "3\\times0+4\\times1+6\\times2+7\\times3=37,\\\\\n",
    "4\\times0+5\\times1+7\\times2+8\\times3=43.\\\\\n",
    "$$\n",
    "\n",
    "下面我们将上述过程实现在`corr2d`函数里。它接受输入数组`X`与核数组`K`，并输出数组`Y`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd, nd\n",
    "from mxnet.gluon import nn as gnn\n",
    "\n",
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = nd.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "def corr2d_torch(X, K):  # 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[19. 25.]\n",
       " [37. 43.]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = nd.array([[0, 1], [2, 3]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = torch.Tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K_t = torch.Tensor([[0, 1], [2, 3]])\n",
    "corr2d_torch(X_t, K_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维卷积层\n",
    "\n",
    "二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。\n",
    "\n",
    "下面基于`corr2d`函数来实现一个自定义的二维卷积层。在构造函数`__init__`里我们声明`weight`和`bias`这两个模型参数。前向计算函数`forward`则是直接调用`corr2d`函数再加上偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(gnn.Block):\n",
    "    def __init__(self, kernal_size, **kwargs):\n",
    "        super(Conv2D, self).__init__(**kwargs)\n",
    "        self.weight = self.params.get('weight',shape=kernal_size)\n",
    "        self.bias = self.params.gte('bias', shape=(1, ))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight.data()) + self.bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D_torch(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D_torch, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d_torch(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积窗口形状为$p \\times q$的卷积层称为$p \\times q$卷积层。同样，$p \\times q$卷积或$p \\times q$卷积核说明卷积核的高和宽分别为$p$和$q$。\n",
    "\n",
    "\n",
    "## 图像中物体边缘检测\n",
    "\n",
    "下面我们来看一个卷积层的简单应用：检测图像中物体的边缘，即找到像素变化的位置。首先我们构造一张$6\\times 8$的图像（即高和宽分别为6像素和8像素的图像）。它中间4列为黑（0），其余为白（1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]]\n",
       "<NDArray 6x8 @cpu(0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们构造一个高和宽分别为1和2的卷积核`K`。当它与输入做互相关运算时，如果横向相邻元素相同，输出为0；否则输出为非0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = nd.array([[1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]]\n",
       "<NDArray 6x7 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = torch.ones((6, 8))\n",
    "X_t[:, 2:6] = 0\n",
    "K_t = torch.Tensor([[1, -1]])\n",
    "Y_t = corr2d_torch(X_t, K_t)\n",
    "Y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由此，我们可以看出，卷积层可通过重复使用卷积核有效地表征局部空间。\n",
    "\n",
    "\n",
    "## 通过数据学习核数组\n",
    "\n",
    "最后我们来看一个例子，它使用物体边缘检测中的输入数据`X`和输出数据`Y`来学习我们构造的核数组`K`。我们首先构造一个卷积层，将其卷积核初始化成随机数组。接下来在每一次迭代中，我们使用平方误差来比较`Y`和卷积层的输出，然后计算梯度来更新权重。简单起见，这里的卷积层忽略了偏差。\n",
    "\n",
    "虽然我们之前构造了`Conv2D`类，但由于`corr2d`使用了对单个元素赋值（`[i, j]=`）的操作因而无法自动求梯度。下面我们使用Gluon提供的`Conv2D`类来实现这个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2, loss 4.949\n",
      "batch 4, loss 0.831\n",
      "batch 6, loss 0.140\n",
      "batch 8, loss 0.024\n",
      "batch 10, loss 0.004\n"
     ]
    }
   ],
   "source": [
    "# 构造一个输出通道为1，核数组形状是(1, 2)的二维卷积层\n",
    "conv2d = gnn.Conv2D(1, kernel_size=(1, 2))\n",
    "conv2d.initialize()\n",
    "\n",
    "# 二维卷积层使用4维输入输出，格式为(barch_size x channel x height x width)，这里批量大小和通道数均为1\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "\n",
    "for i in range(10):\n",
    "    with autograd.record():\n",
    "        Y_hat = conv2d(X)\n",
    "        l = (Y_hat - Y) ** 2\n",
    "    l.backward()\n",
    "    # 简单起见，这里忽略了偏差\n",
    "    conv2d.weight.data()[:] -= 3e-2 * conv2d.weight.grad()\n",
    "    if(i + 1) % 2 == 0:\n",
    "        print('batch %d, loss %.3f' % (i + 1, l.sum().asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.9895    -0.9873705]]\n",
       "<NDArray 1x2 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data().reshape((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5, loss 2.339\n",
      "batch 10, loss 0.424\n",
      "batch 15, loss 0.078\n",
      "batch 20, loss 0.014\n"
     ]
    }
   ],
   "source": [
    "conv2d_torch = Conv2D_torch(kernel_size=(1, 2))\n",
    "\n",
    "for i in range(20):\n",
    "    Y_hat = conv2d_torch(X_t)\n",
    "    l = ((Y_hat - Y_t) ** 2).sum()\n",
    "    l.backward()\n",
    "    \n",
    "    conv2d_torch.weight.data -= 8e-3 * conv2d_torch.weight.grad\n",
    "    conv2d_torch.bias.data -= 8e-3 * conv2d_torch.bias.grad\n",
    "    \n",
    "    conv2d_torch.weight.grad.fill_(0)\n",
    "    conv2d_torch.bias.grad.fill_(0)\n",
    "    \n",
    "    if(i + 1) % 5 == 0:\n",
    "        print('batch %d, loss %.3f' % (i + 1, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9752, -1.0099]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_torch.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，学到的核数组与我们之前定义的核数组`K`较接近。\n",
    "\n",
    "## 互相关运算和卷积运算\n",
    "\n",
    "实际上，卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。\n",
    "\n",
    "那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。为了解释这一点，假设卷积层使用互相关运算学出图5.1中的核数组。设其他条件不变，使用卷积运算学出的核数组即图5.1中的核数组按上下、左右翻转。也就是说，图5.1中的输入与学出的已翻转的核数组再做卷积运算时，依然得到图5.1中的输出。为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。\n",
    "\n",
    "\n",
    "## 特征图和感受野\n",
    "\n",
    "二维卷积层输出的二维数组可以看作输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素$x$的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做$x$的感受野（receptive field）。以图5.1为例，输入中阴影部分的4个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为$2 \\times 2$的输出记为$Y$，并考虑一个更深的卷积神经网络：将$Y$与另一个形状为$2 \\times 2$的核数组做互相关运算，输出单个元素$z$。那么，$z$在$Y$上的感受野包括$Y$的全部4个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。\n",
    "\n",
    "我们常使用“元素”一词来描述数组或矩阵中的成员。在神经网络的术语中，这些元素也可称为“单元”。当含义明确时，本书不对这两个术语做严格区分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "* 构造一个输入图像`X`，令它有水平方向的边缘。如何设计卷积核`K`来检测图像中水平边缘？如果是对角方向的边缘呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.]]),\n",
       " tensor([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.,  1.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [-1., -1., -1., -1., -1., -1.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_l = torch.ones((8, 6))\n",
    "X_l[2:6, :] = 0\n",
    "K_l = torch.Tensor([[1, -1]]).reshape(-1, 1)\n",
    "Y_l = corr2d_torch(X_l, K_l)\n",
    "X_l, Y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0.],\n",
       "         [0., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 1., 1., 1.]]),\n",
       " tensor([[ 0.,  0.,  1.,  1.,  0.],\n",
       "         [ 0.,  0.,  0.,  1.,  1.],\n",
       "         [-1.,  0.,  0.,  0.,  1.],\n",
       "         [-1., -1.,  0.,  0.,  0.],\n",
       "         [ 0., -1., -1.,  0.,  0.]]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_l = torch.Tensor([[1., 1., 1., 0., 0., 0.],\n",
    "                    [1., 1., 1., 1., 0., 0.],\n",
    "                    [1., 1., 1., 1., 1., 0.],\n",
    "                    [0., 1., 1., 1., 1., 1.],\n",
    "                    [0., 0., 1., 1., 1., 1.],\n",
    "                    [0., 0., 0., 1., 1., 1.],])\n",
    "\n",
    "K_l = torch.Tensor([[0, -1], [1 , 0]]).reshape(2, 2)\n",
    "Y_l = corr2d_torch(X_l, K_l)\n",
    "X_l, Y_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 试着对我们自己构造的`Conv2D`类进行自动求梯度，会有什么样的错误信息？在该类的`forward`函数里，将`corr2d`函数替换成`nd.Convolution`类使得自动求梯度变得可行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D_ex3(gnn.Block):\n",
    "    \n",
    "    \"\"\"\n",
    "      - **data**: *(batch_size, channel, height, width)*\n",
    "      - **weight**: *(num_filter, channel, kernel[0], kernel[1])*\n",
    "      - **bias**: *(num_filter,)*\n",
    "      - **out**: *(batch_size, num_filter, out_height, out_width)*.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels, kernel_size, **kwargs):\n",
    "        super(Conv2D_ex3, self).__init__(**kwargs)\n",
    "        self.weight = self.params.get('weight',shape=(channels, 1, ) + kernel_size)\n",
    "        self.bias = self.params.get('bias', shape=(channels, ))\n",
    "        self.num_filter = channels\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return nd.Convolution(data=x, weight=self.weight.data(), bias=self.bias.data(),\n",
    "                              kernel=self.kernel_size, num_filter=self.num_filter, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2, loss 4.877\n",
      "batch 4, loss 0.889\n",
      "batch 6, loss 0.202\n",
      "batch 8, loss 0.079\n",
      "batch 10, loss 0.055\n"
     ]
    }
   ],
   "source": [
    "# 构造一个输出通道为1，核数组形状是(1, 2)的二维卷积层\n",
    "conv2d_ex3 = Conv2D_ex3(channels=1, kernel_size=(1, 2))\n",
    "conv2d_ex3.initialize()\n",
    "\n",
    "# 二维卷积层使用4维输入输出，格式为(barch_size x channel x height x width)，这里批量大小和通道数均为1\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "\n",
    "for i in range(10):\n",
    "    with autograd.record():\n",
    "        Y_hat = conv2d_ex3(X)\n",
    "        l = (Y_hat - Y) ** 2\n",
    "    l.backward()\n",
    "    # 简单起见，这里忽略了偏差\n",
    "    conv2d_ex3.weight.data()[:] -= 3e-2 * conv2d_ex3.weight.grad()\n",
    "    if(i + 1) % 2 == 0:\n",
    "        print('batch %d, loss %.3f' % (i + 1, l.sum().asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.96571404 -1.0117328 ]]\n",
       "<NDArray 1x2 @cpu(0)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_ex3.weight.data().reshape((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function Convolution:\n",
      "\n",
      "Convolution(data=None, weight=None, bias=None, kernel=_Null, stride=_Null, dilate=_Null, pad=_Null, num_filter=_Null, num_group=_Null, workspace=_Null, no_bias=_Null, cudnn_tune=_Null, cudnn_off=_Null, layout=_Null, out=None, name=None, **kwargs)\n",
      "    Compute *N*-D convolution on *(N+2)*-D input.\n",
      "    \n",
      "    In the 2-D convolution, given input data with shape *(batch_size,\n",
      "    channel, height, width)*, the output is computed by\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "       out[n,i,:,:] = bias[i] + \\sum_{j=0}^{channel} data[n,j,:,:] \\star\n",
      "       weight[i,j,:,:]\n",
      "    \n",
      "    where :math:`\\star` is the 2-D cross-correlation operator.\n",
      "    \n",
      "    For general 2-D convolution, the shapes are\n",
      "    \n",
      "    - **data**: *(batch_size, channel, height, width)*\n",
      "    - **weight**: *(num_filter, channel, kernel[0], kernel[1])*\n",
      "    - **bias**: *(num_filter,)*\n",
      "    - **out**: *(batch_size, num_filter, out_height, out_width)*.\n",
      "    \n",
      "    Define::\n",
      "    \n",
      "      f(x,k,p,s,d) = floor((x+2*p-d*(k-1)-1)/s)+1\n",
      "    \n",
      "    then we have::\n",
      "    \n",
      "      out_height=f(height, kernel[0], pad[0], stride[0], dilate[0])\n",
      "      out_width=f(width, kernel[1], pad[1], stride[1], dilate[1])\n",
      "    \n",
      "    If ``no_bias`` is set to be true, then the ``bias`` term is ignored.\n",
      "    \n",
      "    The default data ``layout`` is *NCHW*, namely *(batch_size, channel, height,\n",
      "    width)*. We can choose other layouts such as *NWC*.\n",
      "    \n",
      "    If ``num_group`` is larger than 1, denoted by *g*, then split the input ``data``\n",
      "    evenly into *g* parts along the channel axis, and also evenly split ``weight``\n",
      "    along the first dimension. Next compute the convolution on the *i*-th part of\n",
      "    the data with the *i*-th weight part. The output is obtained by concatenating all\n",
      "    the *g* results.\n",
      "    \n",
      "    1-D convolution does not have *height* dimension but only *width* in space.\n",
      "    \n",
      "    - **data**: *(batch_size, channel, width)*\n",
      "    - **weight**: *(num_filter, channel, kernel[0])*\n",
      "    - **bias**: *(num_filter,)*\n",
      "    - **out**: *(batch_size, num_filter, out_width)*.\n",
      "    \n",
      "    3-D convolution adds an additional *depth* dimension besides *height* and\n",
      "    *width*. The shapes are\n",
      "    \n",
      "    - **data**: *(batch_size, channel, depth, height, width)*\n",
      "    - **weight**: *(num_filter, channel, kernel[0], kernel[1], kernel[2])*\n",
      "    - **bias**: *(num_filter,)*\n",
      "    - **out**: *(batch_size, num_filter, out_depth, out_height, out_width)*.\n",
      "    \n",
      "    Both ``weight`` and ``bias`` are learnable parameters.\n",
      "    \n",
      "    There are other options to tune the performance.\n",
      "    \n",
      "    - **cudnn_tune**: enable this option leads to higher startup time but may give\n",
      "      faster speed. Options are\n",
      "    \n",
      "      - **off**: no tuning\n",
      "      - **limited_workspace**:run test and pick the fastest algorithm that doesn't\n",
      "        exceed workspace limit.\n",
      "      - **fastest**: pick the fastest algorithm and ignore workspace limit.\n",
      "      - **None** (default): the behavior is determined by environment variable\n",
      "        ``MXNET_CUDNN_AUTOTUNE_DEFAULT``. 0 for off, 1 for limited workspace\n",
      "        (default), 2 for fastest.\n",
      "    \n",
      "    - **workspace**: A large number leads to more (GPU) memory usage but may improve\n",
      "      the performance.\n",
      "    \n",
      "    \n",
      "    \n",
      "    Defined in src/operator/nn/convolution.cc:L469\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : NDArray\n",
      "        Input data to the ConvolutionOp.\n",
      "    weight : NDArray\n",
      "        Weight matrix.\n",
      "    bias : NDArray\n",
      "        Bias parameter.\n",
      "    kernel : Shape(tuple), required\n",
      "        Convolution kernel size: (w,), (h, w) or (d, h, w)\n",
      "    stride : Shape(tuple), optional, default=[]\n",
      "        Convolution stride: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.\n",
      "    dilate : Shape(tuple), optional, default=[]\n",
      "        Convolution dilate: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.\n",
      "    pad : Shape(tuple), optional, default=[]\n",
      "        Zero pad for convolution: (w,), (h, w) or (d, h, w). Defaults to no padding.\n",
      "    num_filter : int (non-negative), required\n",
      "        Convolution filter(channel) number\n",
      "    num_group : int (non-negative), optional, default=1\n",
      "        Number of group partitions.\n",
      "    workspace : long (non-negative), optional, default=1024\n",
      "        Maximum temporary workspace allowed (MB) in convolution.This parameter has two usages. When CUDNN is not used, it determines the effective batch size of the convolution kernel. When CUDNN is used, it controls the maximum temporary storage used for tuning the best CUDNN kernel when `limited_workspace` strategy is used.\n",
      "    no_bias : boolean, optional, default=0\n",
      "        Whether to disable bias parameter.\n",
      "    cudnn_tune : {None, 'fastest', 'limited_workspace', 'off'},optional, default='None'\n",
      "        Whether to pick convolution algo by running performance test.\n",
      "    cudnn_off : boolean, optional, default=0\n",
      "        Turn off cudnn for this layer.\n",
      "    layout : {None, 'NCDHW', 'NCHW', 'NCW', 'NDHWC', 'NHWC'},optional, default='None'\n",
      "        Set layout for input, output and weight. Empty for\n",
      "        default layout: NCW for 1d, NCHW for 2d and NCDHW for 3d.NHWC and NDHWC are only supported on GPU.\n",
      "    \n",
      "    out : NDArray, optional\n",
      "        The output NDArray to hold the result.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : NDArray or list of NDArrays\n",
      "        The output of this function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nd.Convolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如何通过变化输入和核数组将互相关运算表示成一个矩阵乘法？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![卷积矩阵实现](./imgs/EmXKun.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如何构造一个全连接层来进行物体边缘检测？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 填充和步幅\n",
    "\n",
    "在上一节的例子里，我们使用高和宽为3的输入与高和宽为2的卷积核得到高和宽为2的输出。一般来说，假设输入形状是$n_h\\times n_w$，卷积核窗口形状是$k_h\\times k_w$，那么输出形状将会是\n",
    "\n",
    "$$(n_h-k_h+1) \\times (n_w-k_w+1).$$\n",
    "\n",
    "所以卷积层的输出形状由输入形状和卷积核窗口形状决定。本节我们将介绍卷积层的两个超参数，即填充和步幅。它们可以对给定形状的输入和卷积核改变输出形状。\n",
    "\n",
    "## 填充\n",
    "\n",
    "填充（padding）是指在输入高和宽的两侧填充元素（通常是0元素）。图5.2里我们在原输入高和宽的两侧分别添加了值为0的元素，使得输入高和宽从3变成了5，并导致输出高和宽由2增加到4。$0\\times0+0\\times1+0\\times2+0\\times3=0$。\n",
    "\n",
    "![在输入的高和宽两侧分别填充了0元素的二维互相关计算](./imgs/padding_strides.gif)\n",
    "\n",
    "一般来说，如果在高的两侧一共填充$p_h$行，在宽的两侧一共填充$p_w$列，那么输出形状将会是\n",
    "\n",
    "$$(n_h-k_h+p_h+1)\\times(n_w-k_w+p_w+1),$$\n",
    "\n",
    "也就是说，输出的高和宽会分别增加$p_h$和$p_w$。\n",
    "\n",
    "在很多情况下，我们会设置$p_h=k_h-1$和$p_w=k_w-1$来使输入和输出具有相同的高和宽。这样会方便在构造网络时推测每个层的输出形状。假设这里$k_h$是奇数，我们会在高的两侧分别填充$p_h/2$行。如果$k_h$是偶数，一种可能是在输入的顶端一侧填充$\\lceil p_h/2\\rceil$行，而在底端一侧填充$\\lfloor p_h/2\\rfloor$行。在宽的两侧填充同理。\n",
    "\n",
    "卷积神经网络经常使用奇数高和宽的卷积核，如1、3、5和7，所以两端上的填充个数相等。对任意的二维数组`X`，设它的第`i`行第`j`列的元素为`X[i,j]`。当两端上的填充个数相等，并使输入和输出具有相同的高和宽时，我们就知道输出`Y[i,j]`是由输入以`X[i,j]`为中心的窗口同卷积核进行互相关计算得到的。\n",
    "\n",
    "下面的例子里我们创建一个高和宽为3的二维卷积层，然后设输入高和宽两侧的填充数分别为1。给定一个高和宽为8的输入，我们发现输出的高和宽也是8。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "# 定义一个函数来计算卷积层。它初始化卷积层权重，并对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    conv2d.initialize()\n",
    "    # (1, 1)代表批量大小和通道数（“多输入通道和多输出通道”一节将介绍）均为1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:])  # 排除不关心的前两维：批量和通道\n",
    "\n",
    "# 注意这里是两侧分别填充1行或列，所以在两侧一共填充2行或列\n",
    "conv2d = nn.Conv2D(1, kernel_size=3, padding=1)\n",
    "X = nd.random.uniform(shape=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2D(1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步幅\n",
    "\n",
    "在上一节里我们介绍了二维互相关运算。卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。我们将每次滑动的行数和列数称为步幅（stride）。\n",
    "\n",
    "目前我们看到的例子里，在高和宽两个方向上步幅均为1。我们也可以使用更大步幅。图5.3展示了在高上步幅为3、在宽上步幅为2的二维互相关运算。可以看到，输出第一列第二个元素时，卷积窗口向下滑动了3行，而在输出第一行第二个元素时卷积窗口向右滑动了2列。当卷积窗口在输入上再向右滑动2列时，由于输入元素无法填满窗口，无结果输出。图5.3中的阴影部分为输出元素及其计算所使用的输入和核数组元素：$0\\times0+0\\times1+1\\times2+2\\times3=8$、$0\\times0+6\\times1+0\\times2+0\\times3=6$。\n",
    "\n",
    "![高和宽上步幅分别为3和2的二维互相关运算](../d2l-zh/img/conv_stride.svg)\n",
    "\n",
    "一般来说，当高上步幅为$s_h$，宽上步幅为$s_w$时，输出形状为\n",
    "\n",
    "$$\\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor.$$\n",
    "\n",
    "如果设置$p_h=k_h-1$和$p_w=k_w-1$，那么输出形状将简化为$\\lfloor(n_h+s_h-1)/s_h\\rfloor \\times \\lfloor(n_w+s_w-1)/s_w\\rfloor$。更进一步，如果输入的高和宽能分别被高和宽上的步幅整除，那么输出形状将是$(n_h/s_h) \\times (n_w/s_w)$。\n",
    "\n",
    "下面我们令高和宽上的步幅均为2，从而使输入的高和宽减半。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多输入通道和多输出通道\n",
    "\n",
    "前面两节里我们用到的输入和输出都是二维数组，但真实数据的维度经常更高。例如，彩色图像在高和宽2个维度外还有RGB（红、绿、蓝）3个颜色通道。假设彩色图像的高和宽分别是$h$和$w$（像素），那么它可以表示为一个$3\\times h\\times w$的多维数组。我们将大小为3的这一维称为通道（channel）维。本节我们将介绍含多个输入通道或多个输出通道的卷积核。\n",
    "\n",
    "\n",
    "\n",
    "## 多输入通道\n",
    "\n",
    "当输入数据含多个通道时，我们需要构造一个输入通道数与输入数据的通道数相同的卷积核，从而能够与含多通道的输入数据做互相关运算。假设输入数据的通道数为$c_i$，那么卷积核的输入通道数同样为$c_i$。设卷积核窗口形状为$k_h\\times k_w$。当$c_i=1$时，我们知道卷积核只包含一个形状为$k_h\\times k_w$的二维数组。当$c_i > 1$时，我们将会为每个输入通道各分配一个形状为$k_h\\times k_w$的核数组。把这$c_i$个数组在输入通道维上连结，即得到一个形状为$c_i\\times k_h\\times k_w$的卷积核。由于输入和卷积核各有$c_i$个通道，我们可以在各个通道上对输入的二维数组和卷积核的二维核数组做互相关运算，再将这$c_i$个互相关运算的二维输出按通道相加，得到一个二维数组。这就是含多个通道的输入数据与多输入通道的卷积核做二维互相关运算的输出。\n",
    "\n",
    "图5.4展示了含2个输入通道的二维互相关计算的例子。在每个通道上，二维输入数组与二维核数组做互相关运算，再按通道相加即得到输出。图5.4中阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：$(1\\times1+2\\times2+4\\times3+5\\times4)+(0\\times0+1\\times1+3\\times2+4\\times3)=56$。\n",
    "\n",
    "![含2个输入通道的互相关计算](../d2l-zh/img/conv_multi_in.svg)\n",
    "\n",
    "\n",
    "接下来我们实现含多个输入通道的互相关运算。我们只需要对每个通道做互相关运算，然后通过`add_n`函数来进行累加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import nd\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 首先沿着X和K的第0维（通道维）遍历。然后使用*将结果列表变成add_n函数的位置参数\n",
    "    # （positional argument）来进行相加\n",
    "    return nd.add_n(*[d2l.corr2d(x, k) for x, k in zip(X, K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 56.  72.]\n",
       " [104. 120.]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.array([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = nd.array([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输出通道\n",
    "\n",
    "当输入通道有多个时，因为我们对各个通道的结果做了累加，所以不论输入通道数是多少，输出通道数总是为1。设卷积核输入通道数和输出通道数分别为$c_i$和$c_o$，高和宽分别为$k_h$和$k_w$。如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为$c_i\\times k_h\\times k_w$的核数组。将它们在输出通道维上连结，卷积核的形状即$c_o\\times c_i\\times k_h\\times k_w$。在做互相关运算时，每个输出通道上的结果由卷积核在该输出通道上的核数组与整个输入数组计算而来。\n",
    "\n",
    "下面我们实现一个互相关运算函数来计算多个通道的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起\n",
    "    return nd.stack(*[corr2d_multi_in(X, k) for k in K])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将核数组K同K+1和K+2连结在一起构造一个输出通道数为3的卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 2, 2)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = nd.stack(K, K + 1, K + 2)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[[ 56.  72.]\n",
       "   [104. 120.]]\n",
       " \n",
       "  [[ 76. 100.]\n",
       "   [148. 172.]]\n",
       " \n",
       "  [[ 96. 128.]\n",
       "   [192. 224.]]]\n",
       " <NDArray 3x2x2 @cpu(0)>,\n",
       " (3, 2, 2))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K), corr2d_multi_in_out(X, K).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $1\\times 1$卷积层\n",
    "\n",
    "最后我们讨论卷积窗口形状为$1\\times 1$（$k_h=k_w=1$）的多通道卷积层。我们通常称之为$1\\times 1$卷积层，并将其中的卷积运算称为$1\\times 1$卷积。因为使用了最小窗口，$1\\times 1$卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能。实际上，$1\\times 1$卷积的主要计算发生在通道维上。图5.5展示了使用输入通道数为3、输出通道数为2的$1\\times 1$卷积核的互相关计算。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本，那么$1\\times 1$卷积层的作用与全连接层等价。\n",
    "\n",
    "![使用输入通道数为3、输出通道数为2的$1\\times 1$卷积核的互相关计算。输入和输出具有相同的高和宽](../d2l-zh/img/conv_1x1.svg)\n",
    "\n",
    "下面我们使用全连接层中的矩阵乘法来实现$1\\times 1$卷积。这里需要在矩阵乘法运算前后对数据形状做一些调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    Y = nd.dot(K, X)  # 全连接层的乘法\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[[0.38098437 0.66436744 0.66814697]\n",
       "   [0.6700994  0.28183377 0.30740768]\n",
       "   [0.77047193 0.28921267 0.53304   ]]\n",
       " \n",
       "  [[1.0817252  1.2138927  0.7843529 ]\n",
       "   [0.8791408  0.54728526 0.47792655]\n",
       "   [1.602026   0.70060664 0.9727361 ]]]\n",
       " <NDArray 2x3x3 @cpu(0)>,\n",
       " \n",
       " [[[0.38098437 0.66436744 0.66814697]\n",
       "   [0.6700994  0.28183377 0.30740765]\n",
       "   [0.77047193 0.28921267 0.53304   ]]\n",
       " \n",
       "  [[1.0817251  1.2138927  0.78435284]\n",
       "   [0.87914085 0.54728526 0.47792658]\n",
       "   [1.602026   0.7006066  0.9727361 ]]]\n",
       " <NDArray 2x3x3 @cpu(0)>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.random.uniform(shape=(3, 3, 3))\n",
    "K = nd.random.uniform(shape=(2, 3, 1, 1))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "\n",
    "Y1, Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y1 - Y2).norm().asscalar() < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
